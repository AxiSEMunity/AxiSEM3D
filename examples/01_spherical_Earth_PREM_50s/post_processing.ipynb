{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 8})\n",
    "\n",
    "from obspy.core import Stream, Trace, UTCDateTime, Stats\n",
    "from obspy.io.sac import SACTrace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read event location\n",
    "with open('./input/inparam.source.yaml', 'r') as file:\n",
    "    source_yaml = yaml.load(file, Loader=yaml.FullLoader)\n",
    "loc_leaf = source_yaml['list_of_sources'][0]['VIRGINIA_201108231751A']['location']\n",
    "event_latlon = loc_leaf['latitude_longitude']\n",
    "event_depth = loc_leaf['depth']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GSN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Station info and map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read station info\n",
    "info_GSN = np.loadtxt('./input/GSN.txt', dtype=str, skiprows=3)\n",
    "\n",
    "####################################\n",
    "# draw a map of event and stations #\n",
    "####################################\n",
    "\n",
    "plt.figure(dpi=150)\n",
    "# draw map\n",
    "map = Basemap(projection='cyl', resolution='l', lon_0=0)\n",
    "map.drawcoastlines(linewidth=0.25)\n",
    "map.fillcontinents(color='ivory',lake_color='lightblue')\n",
    "map.drawmapboundary(fill_color='lightblue', linewidth=0)\n",
    "# draw event\n",
    "map.scatter(event_latlon[1], event_latlon[0], latlon=True, \n",
    "            s=150, c='r', marker='*', lw=0, zorder=100)\n",
    "# draw stations\n",
    "map.scatter(info_GSN[:, 3].astype(float), info_GSN[:, 2].astype(float), latlon=True, \n",
    "            s=30, c='b', marker=7, lw=0, zorder=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and plot seismograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify a station key (network.name)\n",
    "station_key = 'IU.ANMO'\n",
    "\n",
    "# read time and displacement\n",
    "gsn_dir = './output/stations/global_seismic_network_GSN'\n",
    "time = np.loadtxt(gsn_dir + '/time_points.ascii')\n",
    "disp = np.loadtxt(gsn_dir + '/%s.ascii' % station_key)\n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots(3, sharex=True, dpi=150)\n",
    "for ich, ch in enumerate('RTZ'):\n",
    "    # change unit to mm\n",
    "    ax[ich].plot(time, disp[:, ich] * 1e6, lw=1)\n",
    "    ax[ich].text(.95, .9, 'channel = ' + ch, transform = ax[ich].transAxes, ha='right', va='top')\n",
    "ax[1].set_ylabel('Amplitude (mm)')\n",
    "ax[0].set_xlim(time[0], time[-1])\n",
    "plt.xlabel('Time after source origin (s)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing using obspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trace header\n",
    "stats = Stats()\n",
    "stats.starttime = UTCDateTime(time[0])\n",
    "stats.delta = UTCDateTime(time[1] - time[0])\n",
    "stats.npts = len(time)\n",
    "\n",
    "# stream\n",
    "stream = Stream()\n",
    "for ich, ch in enumerate('RTZ'):\n",
    "    stats.channel = ch   \n",
    "    stream.append(Trace(disp[:, ich], header=stats))\n",
    "\n",
    "# process (filter, resample, slice, ...)\n",
    "stream.filter('lowpass', freq=1/50)\n",
    "stream.resample(1.)\n",
    "stream = stream.slice(UTCDateTime(0.), UTCDateTime(1800.))\n",
    "\n",
    "# print & plot\n",
    "print(stream)\n",
    "stream.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to SAC after down-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create dir\n",
    "os.makedirs(gsn_dir + '/sac', exist_ok=True)\n",
    "\n",
    "# sac header\n",
    "sac_header = {}\n",
    "sac_header['evla'] = event_latlon[0]\n",
    "sac_header['evlo'] = event_latlon[1]\n",
    "sac_header['evdp'] = float(event_depth) / 1e3\n",
    "\n",
    "# loop over stations\n",
    "print('Saving to SAC...')\n",
    "for ist, st in enumerate(info_GSN):\n",
    "    print('%d / %d' % (ist + 1, len(info_GSN)), end='\\r')\n",
    "    # sac header\n",
    "    sac_header['kstnm'] = st[0]\n",
    "    sac_header['knetwk'] = st[1]\n",
    "    sac_header['stla'] = float(st[2])\n",
    "    sac_header['stlo'] = float(st[3])\n",
    "    sac_header['stdp'] = float(st[5])\n",
    "    # read data\n",
    "    disp = np.loadtxt(gsn_dir + '/%s.%s.ascii' % (st[1], st[0]))\n",
    "    # loop over channels\n",
    "    for ich, ch in enumerate('RTZ'):\n",
    "        # sac header\n",
    "        sac_header['kcmpnm'] = ch\n",
    "        # add sac header to trace header\n",
    "        stats.sac = sac_header\n",
    "        # create and process trace\n",
    "        tr = Trace(data=disp[:, ich], header=stats)\n",
    "        tr.resample(1.)\n",
    "        tr = tr.slice(UTCDateTime(0.), UTCDateTime(1800.))\n",
    "        # create sac from trace\n",
    "        sac = SACTrace.from_obspy_trace(tr)\n",
    "        sac.write(gsn_dir + '/sac/%s.%s.%s.sac' % (st[1], st[0], ch))\n",
    "print('Done with %d stations.' % len(info_GSN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USArray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Station info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read station locations\n",
    "info_US_TA = np.loadtxt('./input/US_TA.txt', dtype=str, skiprows=3)\n",
    "\n",
    "# dict: station key -> [lat, lon]\n",
    "nstation = len(info_US_TA)\n",
    "stlatlon_dict = {}\n",
    "for ist in np.arange(nstation):\n",
    "    key = info_US_TA[ist, 1] + '.' + info_US_TA[ist, 0]\n",
    "    stlatlon_dict[key] = np.array([float(info_US_TA[ist, 2]), float(info_US_TA[ist, 3])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank-to-station map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data dir\n",
    "us_ta_dir = './output/stations/USArray_transportable'\n",
    "\n",
    "# read rank-station info\n",
    "rank_station_info = np.loadtxt(us_ta_dir + '/rank_station.info', dtype=str, skiprows=1)\n",
    "\n",
    "# dict: mpi-rank -> [station keys]\n",
    "rank_station_dict = {}\n",
    "\n",
    "# (lat, lon) of stations re-ordered by data\n",
    "stlatlon_data_order = []\n",
    "\n",
    "for item in rank_station_info:\n",
    "    rank = item[0]\n",
    "    stkey = item[1]\n",
    "    # initialize with an empty array if rank does not exists in rank_station_dict\n",
    "    if rank not in rank_station_dict.keys():\n",
    "        rank_station_dict[rank] = []\n",
    "    # append the station\n",
    "    rank_station_dict[rank].append(stkey)\n",
    "    stlatlon_data_order.append(stlatlon_dict[stkey])\n",
    "    \n",
    "# convert to numpy array\n",
    "stlatlon_data_order = np.array(stlatlon_data_order)\n",
    "\n",
    "# read time\n",
    "time = np.loadtxt(us_ta_dir + '/time_points.ascii')\n",
    "ntime = len(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Animations on array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a channel to animate\n",
    "# U3   -- vertical displacement\n",
    "# E_I1 -- trace of strain\n",
    "# R3   -- vertical rotation\n",
    "channel = 'R3'\n",
    "\n",
    "# colormap norm in animation\n",
    "if channel == 'U3':\n",
    "    norm = 1e-6\n",
    "elif channel == 'E_I1':\n",
    "    norm = 1e-11\n",
    "elif channel == 'R3':\n",
    "    norm = 1e-11\n",
    "else:\n",
    "    assert False, \"Invalid channel.\"\n",
    "    \n",
    "# allocate data\n",
    "data = np.ndarray((ntime, nstation))\n",
    "\n",
    "# loop over mpi-ranks to read data\n",
    "for rank in rank_station_dict.keys():\n",
    "    data_on_rank = np.loadtxt('%s/dir_rank%s/%s.ascii' % (us_ta_dir, rank, channel))\n",
    "    data[:, 0:len(rank_station_dict[rank])] = data_on_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "###### plot a snapshot ######\n",
    "#############################\n",
    "\n",
    "# specify a time step (0~384)\n",
    "tstep = 100\n",
    "\n",
    "# plot the snapshot\n",
    "plt.figure(dpi=150)\n",
    "plt.gca().axis('off')\n",
    "plt.scatter(stlatlon_data_order[:, 1], stlatlon_data_order[:, 0], s=1, \n",
    "            c=data[tstep, :], vmin=-norm, vmax=norm, cmap='coolwarm')\n",
    "plt.text(0, 0, 'Time = %.1f s' % (time[tstep]), transform = plt.gca().transAxes)\n",
    "plt.colorbar(orientation='vertical', shrink=.5, label=channel)\n",
    "plt.gca().set_aspect(1.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "###### make animation ######\n",
    "############################\n",
    "\n",
    "# create dir\n",
    "os.makedirs(us_ta_dir + '/animation', exist_ok=True)\n",
    "\n",
    "# create all snapshots\n",
    "print('Making snapshots...')\n",
    "for tstep in np.arange(len(time)):\n",
    "    print('%d / %d' % (tstep + 1, len(time)), end='\\r')\n",
    "    plt.figure(dpi=150)\n",
    "    plt.gca().axis('off')\n",
    "    plt.scatter(stlatlon_data_order[:, 1], stlatlon_data_order[:, 0], s=1, \n",
    "                c=data[tstep, :], vmin=-norm, vmax=norm, cmap='coolwarm')\n",
    "    plt.text(0, 1, 'Time = %.1f s' % (time[tstep]), transform = plt.gca().transAxes)\n",
    "    plt.colorbar(orientation='vertical', shrink=.5, label=channel)\n",
    "    plt.gca().set_aspect(1.3)\n",
    "    plt.savefig(us_ta_dir + '/animation/%s.%04d.png' % (channel, tstep))\n",
    "    plt.close()\n",
    "    \n",
    "# use ffmepg to combine snapshots to animation\n",
    "print('Creating vedio using ffmpeg...')\n",
    "os.system(\"ffmpeg -y -i %s/animation/%s.%%04d.png %s/animation/%s.mp4\" % \n",
    "          (us_ta_dir, channel, us_ta_dir, channel))\n",
    "\n",
    "# remove snapshots\n",
    "os.system('rm ' + us_ta_dir + '/animation/%s.*.png' % (channel,))\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# play animation\n",
    "from IPython.display import Video\n",
    "Video(\"%s/animation/%s.mp4\" % (us_ta_dir, channel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
